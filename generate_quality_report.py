#!/usr/bin/env python3
"""
å¯¹è¯è´¨é‡æŠ¥å‘Šç”Ÿæˆå·¥å…·

åŠŸèƒ½ï¼š
1. ç”Ÿæˆå¯¹è¯è´¨é‡ Markdown æŠ¥å‘Š
2. ç”Ÿæˆæ„å›¾åˆ†å¸ƒé¥¼å›¾
3. ç”Ÿæˆè´¨é‡è¯„åˆ†è¶‹åŠ¿å›¾
4. ç”Ÿæˆæ¨èæ•ˆæœåˆ†æ
"""

import json
from typing import Dict, Any, List
from datetime import datetime
import os


def generate_markdown_report(analytics: Dict[str, Any], output_file: str = "quality_report.md"):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„è´¨é‡æŠ¥å‘Š"""
    
    report_lines = []
    
    # æ ‡é¢˜
    report_lines.append("# å¯¹è¯è´¨é‡åˆ†ææŠ¥å‘Š")
    report_lines.append(f"\n**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"\n**ä¼šè¯ID**: {analytics.get('session_id', 'N/A')}")
    report_lines.append("\n---\n")
    
    # 1. è´¨é‡æŒ‡æ ‡æ€»è§ˆ
    quality = analytics.get('quality_metrics', {})
    if quality:
        report_lines.append("## ğŸ“Š è´¨é‡æŒ‡æ ‡æ€»è§ˆ\n")
        report_lines.append(f"### ç»¼åˆè¯„åˆ†: **{quality.get('quality_score', 0)}/100**\n")
        
        score = quality.get('quality_score', 0)
        if score >= 80:
            grade = "ğŸ† ä¼˜ç§€"
            comment = "å¯¹è¯è´¨é‡éå¸¸å‡ºè‰²ï¼"
        elif score >= 60:
            grade = "âœ… è‰¯å¥½"
            comment = "å¯¹è¯è´¨é‡è¾ƒå¥½ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚"
        elif score >= 40:
            grade = "âš ï¸ åŠæ ¼"
            comment = "å¯¹è¯è´¨é‡å°šå¯ï¼Œéœ€è¦æ”¹è¿›ã€‚"
        else:
            grade = "âŒ è¾ƒå·®"
            comment = "å¯¹è¯è´¨é‡éœ€è¦å¤§å¹…ä¼˜åŒ–ã€‚"
        
        report_lines.append(f"**è¯„çº§**: {grade}\n")
        report_lines.append(f"**è¯„ä»·**: {comment}\n")
        
        # æ•ˆç‡æŒ‡æ ‡
        efficiency = quality.get('efficiency', {})
        report_lines.append("\n### æ•ˆç‡æŒ‡æ ‡\n")
        report_lines.append(f"- **å¹³å‡å“åº”æ—¶é—´**: {efficiency.get('avg_response_time', 0)}ç§’")
        report_lines.append(f"- **å¹³å‡å·¥å…·è°ƒç”¨**: {efficiency.get('avg_tool_calls', 0)}æ¬¡")
        report_lines.append(f"- **æ€»å·¥å…·è°ƒç”¨**: {efficiency.get('total_tool_calls', 0)}æ¬¡\n")
        
        # ä»»åŠ¡å®Œæˆåº¦
        completion = quality.get('task_completion', {})
        report_lines.append("\n### ä»»åŠ¡å®Œæˆåº¦\n")
        report_lines.append(f"- **æˆåŠŸä»»åŠ¡**: {completion.get('successful_tasks', 0)}ä¸ª")
        report_lines.append(f"- **å¤±è´¥ä»»åŠ¡**: {completion.get('failed_tasks', 0)}ä¸ª")
        report_lines.append(f"- **æˆåŠŸç‡**: {completion.get('success_rate', 0)*100:.1f}%\n")
        
        # å¯¹è¯è´¨é‡
        conv_quality = quality.get('conversation_quality', {})
        report_lines.append("\n### å¯¹è¯æµç•…åº¦\n")
        report_lines.append(f"- **æ¾„æ¸…ç‡**: {conv_quality.get('clarification_rate', 0)*100:.1f}%")
        report_lines.append(f"  - âœ… è¶Šä½è¶Šå¥½ï¼ˆè¡¨ç¤ºå¯¹è¯æ¸…æ™°æ˜ç¡®ï¼‰")
        report_lines.append(f"- **ä¸»åŠ¨å¼•å¯¼ç‡**: {conv_quality.get('proactive_rate', 0)*100:.1f}%")
        report_lines.append(f"  - âœ… è¶Šé«˜è¶Šå¥½ï¼ˆè¡¨ç¤ºAgentä¸»åŠ¨å¸®åŠ©ç”¨æˆ·ï¼‰\n")
    
    # 2. æ„å›¾åˆ†æ
    intent = analytics.get('intent_analysis', {})
    if intent:
        report_lines.append("\n## ğŸ¯ æ„å›¾åˆ†æ\n")
        report_lines.append(f"**æ€»å¯¹è¯è½®æ¬¡**: {intent.get('total_turns', 0)}\n")
        
        # æ„å›¾åˆ†å¸ƒ
        intent_dist = intent.get('intent_distribution', {})
        if intent_dist:
            report_lines.append("\n### æ„å›¾åˆ†å¸ƒ\n")
            report_lines.append("| æ„å›¾ç±»å‹ | å‡ºç°æ¬¡æ•° | å æ¯” |")
            report_lines.append("|---------|---------|------|")
            
            total_intents = sum(intent_dist.values())
            for intent_type, count in sorted(intent_dist.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_intents * 100) if total_intents > 0 else 0
                report_lines.append(f"| {intent_type} | {count} | {percentage:.1f}% |")
            report_lines.append("")
        
        # å¤åˆæ„å›¾
        composite = intent.get('composite_intents', [])
        if composite:
            report_lines.append("\n### ğŸ”„ å¤åˆæ„å›¾æ£€æµ‹\n")
            for comp in composite:
                report_lines.append(f"**{comp.get('name', 'Unknown')}**")
                report_lines.append(f"- æè¿°: {comp.get('description', 'N/A')}")
                report_lines.append(f"- ç½®ä¿¡åº¦: {comp.get('confidence', 0):.2f}")
                report_lines.append(f"- å­æ„å›¾: {', '.join(comp.get('sub_intents', []))}\n")
        
        # å½“å‰çŠ¶æ€å’Œé¢„æµ‹
        report_lines.append("\n### å½“å‰çŠ¶æ€\n")
        report_lines.append(f"- **å½“å‰æ„å›¾**: {intent.get('current_intent', 'N/A')}")
        predicted = intent.get('predicted_next', [])
        if predicted:
            report_lines.append(f"- **é¢„æµ‹ä¸‹ä¸€æ­¥**: {', '.join(predicted)}\n")
    
    # 3. å¯¹è¯çŠ¶æ€
    conv_state = analytics.get('conversation_state', {})
    if conv_state:
        report_lines.append("\n## ğŸ›’ å¯¹è¯çŠ¶æ€\n")
        report_lines.append(f"**å½“å‰é˜¶æ®µ**: {conv_state.get('current_stage', 'N/A')}\n")
        
        # ç”¨æˆ·ä¸Šä¸‹æ–‡
        user_ctx = conv_state.get('user_context', {})
        if user_ctx:
            report_lines.append("\n### ç”¨æˆ·ä¸Šä¸‹æ–‡\n")
            report_lines.append(f"- **ç”¨æˆ·ID**: {user_ctx.get('user_id', 'æœªç™»å½•')}")
            report_lines.append(f"- **VIPçŠ¶æ€**: {'æ˜¯' if user_ctx.get('is_vip') else 'å¦'}")
            report_lines.append(f"- **è´­ç‰©è½¦å•†å“**: {user_ctx.get('cart_item_count', 0)}ä»¶")
            
            viewed = user_ctx.get('last_viewed_products', [])
            if viewed:
                report_lines.append(f"- **æœ€è¿‘æµè§ˆ**: {', '.join(map(str, viewed[:5]))}")
            
            order_id = user_ctx.get('recent_order_id')
            if order_id:
                report_lines.append(f"- **æœ€è¿‘è®¢å•**: {order_id}\n")
    
    # 4. æ”¹è¿›å»ºè®®
    report_lines.append("\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n")
    
    if quality:
        score = quality.get('quality_score', 0)
        efficiency = quality.get('efficiency', {})
        conv_quality = quality.get('conversation_quality', {})
        
        if efficiency.get('avg_response_time', 0) > 5:
            report_lines.append("- âš ï¸ **å“åº”æ—¶é—´è¾ƒé•¿**ï¼šå»ºè®®ä¼˜åŒ–å·¥å…·è°ƒç”¨é€»è¾‘ï¼Œå‡å°‘ä¸å¿…è¦çš„APIè¯·æ±‚")
        
        if efficiency.get('avg_tool_calls', 0) > 3:
            report_lines.append("- âš ï¸ **å·¥å…·è°ƒç”¨è¿‡å¤š**ï¼šå»ºè®®ä¼˜åŒ–æ¨ç†é“¾ï¼Œåˆå¹¶ç›¸å…³å·¥å…·è°ƒç”¨")
        
        if conv_quality.get('clarification_rate', 0) > 0.5:
            report_lines.append("- âš ï¸ **æ¾„æ¸…ç‡è¾ƒé«˜**ï¼šå»ºè®®æ”¹è¿›æ„å›¾è¯†åˆ«ï¼Œå‡å°‘åå¤è¯¢é—®")
        
        if conv_quality.get('proactive_rate', 0) < 0.3:
            report_lines.append("- âš ï¸ **ä¸»åŠ¨å¼•å¯¼ä¸è¶³**ï¼šå»ºè®®å¢å¼ºä¸»åŠ¨æœåŠ¡æ„è¯†ï¼Œæä¾›æ›´å¤šå»ºè®®")
        
        completion = quality.get('task_completion', {})
        if completion.get('success_rate', 0) < 0.6:
            report_lines.append("- âš ï¸ **ä»»åŠ¡å®Œæˆç‡ä½**ï¼šå»ºè®®æ£€æŸ¥å·¥å…·å®ç°ï¼Œæå‡ä»»åŠ¡æˆåŠŸç‡")
        
        if not any("âš ï¸" in line for line in report_lines[-5:]):
            report_lines.append("- âœ… **è¡¨ç°è‰¯å¥½**ï¼šç»§ç»­ä¿æŒå½“å‰è´¨é‡æ°´å¹³ï¼")
    
    # å†™å…¥æ–‡ä»¶
    report_content = "\n".join(report_lines)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    return output_file


def generate_ascii_chart(data: Dict[str, int], title: str = "åˆ†å¸ƒå›¾") -> str:
    """ç”Ÿæˆç®€å•çš„ ASCII æŸ±çŠ¶å›¾"""
    lines = []
    lines.append(f"\n{title}")
    lines.append("=" * 50)
    
    if not data:
        lines.append("(æ— æ•°æ®)")
        return "\n".join(lines)
    
    max_value = max(data.values()) if data else 1
    max_label_len = max(len(str(k)) for k in data.keys()) if data else 0
    
    for label, value in sorted(data.items(), key=lambda x: x[1], reverse=True):
        bar_length = int((value / max_value) * 30) if max_value > 0 else 0
        bar = "â–ˆ" * bar_length
        lines.append(f"{label:>{max_label_len}} | {bar} {value}")
    
    lines.append("=" * 50)
    return "\n".join(lines)


def generate_text_report(analytics: Dict[str, Any]) -> str:
    """ç”Ÿæˆçº¯æ–‡æœ¬æŠ¥å‘Šï¼ˆç”¨äºç»ˆç«¯è¾“å‡ºï¼‰"""
    lines = []
    
    lines.append("\n" + "="*60)
    lines.append("  å¯¹è¯è´¨é‡åˆ†ææŠ¥å‘Š")
    lines.append("="*60)
    
    # è´¨é‡æŒ‡æ ‡
    quality = analytics.get('quality_metrics', {})
    if quality:
        lines.append(f"\nğŸ“Š ç»¼åˆè¯„åˆ†: {quality.get('quality_score', 0)}/100")
        lines.append(f"â±ï¸  å¹³å‡å“åº”: {quality.get('efficiency', {}).get('avg_response_time', 0):.2f}ç§’")
        lines.append(f"ğŸ”§ å¹³å‡å·¥å…·: {quality.get('efficiency', {}).get('avg_tool_calls', 0):.2f}æ¬¡")
        lines.append(f"âœ… æˆåŠŸç‡: {quality.get('task_completion', {}).get('success_rate', 0)*100:.1f}%")
    
    # æ„å›¾åˆ†å¸ƒå›¾
    intent = analytics.get('intent_analysis', {})
    if intent and intent.get('intent_distribution'):
        lines.append(generate_ascii_chart(
            intent['intent_distribution'],
            "\nğŸ¯ æ„å›¾åˆ†å¸ƒ"
        ))
    
    # å¤åˆæ„å›¾
    if intent and intent.get('composite_intents'):
        lines.append("\nğŸ”„ å¤åˆæ„å›¾:")
        for comp in intent['composite_intents']:
            lines.append(f"  - {comp.get('name')}: {comp.get('description')}")
    
    lines.append("\n" + "="*60)
    return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°ï¼šè¯»å–æµ‹è¯•è¾“å‡ºå¹¶ç”ŸæˆæŠ¥å‘Š"""
    
    # è¯»å–æµ‹è¯•è¾“å‡º
    test_output_file = "test_analytics_output.json"
    
    if not os.path.exists(test_output_file):
        print(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•è¾“å‡ºæ–‡ä»¶: {test_output_file}")
        print("è¯·å…ˆè¿è¡Œ test_phase4_advanced.py")
        return 1
    
    with open(test_output_file, 'r', encoding='utf-8') as f:
        analytics = json.load(f)
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Šï¼ˆç»ˆç«¯è¾“å‡ºï¼‰
    print(generate_text_report(analytics))
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    md_file = generate_markdown_report(analytics, "quality_report.md")
    print(f"\nâœ… Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {md_file}")
    
    # ç”Ÿæˆè¯¦ç»†çš„ JSON æŠ¥å‘Š
    detailed_file = "quality_report_detailed.json"
    with open(detailed_file, 'w', encoding='utf-8') as f:
        json.dump(analytics, f, indent=2, ensure_ascii=False)
    print(f"âœ… è¯¦ç»† JSON æŠ¥å‘Šå·²ç”Ÿæˆ: {detailed_file}")
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
